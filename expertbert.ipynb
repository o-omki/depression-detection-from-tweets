{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i04hc7hgY07B"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWmkn7WcYzqn"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U \"tensorflow-text\"\n",
        "!pip install -q -U tf-models-official\n",
        "!pip install -U tfds-nightly\n",
        "!pip install -U tensorflow-addons\n",
        "!pip install -q tf-models-official\n",
        "!pip install -U tensorboard_plugin_profile\n",
        "!pip install tensorflow pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkzC4esaG-Fr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp import optimization\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from datetime import datetime\n",
        "import tensorboard as tb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QEnIoqTHCoF"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wn9h0qSHFQn"
      },
      "outputs": [],
      "source": [
        "# if os.environ[\"COLAB_TPU_ADDR\"] :\n",
        "#     cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"\")\n",
        "#     tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#     tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#     strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#     print(\"Using TPU\")\n",
        "\n",
        "gpus = tf.config.list_logical_devices(\"GPU\")\n",
        "strategy = tf.distribute.MirroredStrategy(gpus)\n",
        "print(\"Using GPU\")\n",
        "\n",
        "# else:\n",
        "#     raise ValueError(\"Avoid running on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc9DYN_QHIzb"
      },
      "outputs": [],
      "source": [
        "PREPROCESSOR_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "BERT_URL = \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\"\n",
        "TB_LOGS_DIR = \"/content/drive/MyDrive/Project/Models50k/sentiment140_expertbert/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "CHKP_DIR = \"/content/drive/MyDrive/Project/Models50k/sentiment140_expertbert/cp.ckpt\"\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "INIT_LR = 2e-5\n",
        "TFDS_NAME = \"sentiment140\"\n",
        "PATIENCE = 2\n",
        "TAKE_SIZE = 120000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euB1FX6kHNVx"
      },
      "outputs": [],
      "source": [
        "# with tf.device(\"/job:localhost\"):\n",
        "in_memory_ds, info = tfds.load(TFDS_NAME, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWYEk3cfOqtT"
      },
      "outputs": [],
      "source": [
        "import tensorboard as tb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVvBdvKROt_k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lYrqnV9l218"
      },
      "outputs": [],
      "source": [
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhFuzX6Co5h7"
      },
      "outputs": [],
      "source": [
        "# in_memory_ds[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n4McFfacdaa"
      },
      "outputs": [],
      "source": [
        "# tfds_info = tfds.builder(TFDS_NAME).info\n",
        "# print(tfds_info)\n",
        "# sentence_features = list(tfds_info.features.keys())\n",
        "# print(f\"Sentence features: {sentence_features}\")\n",
        "\n",
        "# sentence_features.remove(\"date\")\n",
        "# sentence_features.remove(\"user\")\n",
        "# sentence_features.remove(\"query\")\n",
        "# sentence_features.remove(\"polarity\")\n",
        "\n",
        "# available_splits = list(tfds_info.splits.keys())\n",
        "# print(f\"Splits: {available_splits}\")\n",
        "# train_split = \"train\"\n",
        "# validation_split = \"validation\"\n",
        "# test_split = \"test\"\n",
        "\n",
        "# num_classes = 2\n",
        "# num_examples = tfds_info.splits.total_num_examples\n",
        "# print(num_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwMiiOVte3Ic"
      },
      "outputs": [],
      "source": [
        "data_dict = in_memory_ds.get(\"train\").take(50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMmYAjYDjKc2"
      },
      "outputs": [],
      "source": [
        "TOTAL_SAMPLES = data_dict.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a2Qt8zKnkI0"
      },
      "outputs": [],
      "source": [
        "test_val_size = int(0.1 * TOTAL_SAMPLES)\n",
        "train_size = int(TOTAL_SAMPLES - 2*test_val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3i1mWLQqhh1"
      },
      "outputs": [],
      "source": [
        "train_data = data_dict.take(train_size)\n",
        "test_data = data_dict.skip(train_size).take(test_val_size)\n",
        "val_data = data_dict.skip(train_size + test_val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBMCC-i-ra7I"
      },
      "outputs": [],
      "source": [
        "test_data.cardinality().numpy()\n",
        "val_data.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110HzNFVuF29"
      },
      "outputs": [],
      "source": [
        "def optimize_dataset(dataset):\n",
        "    return dataset.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArXvArgKX1Zy"
      },
      "outputs": [],
      "source": [
        "train_data = optimize_dataset(train_data.map(lambda x: (x.get(\"text\"), 0 if (x.get(\"polarity\")) == 0 else 1)))\n",
        "test_data = optimize_dataset(test_data.map(lambda x: (x.get(\"text\"), 0 if (x.get(\"polarity\")) == 0 else 1)))    \n",
        "val_data = optimize_dataset(val_data.map(lambda x: (x.get(\"text\"), 0 if (x.get(\"polarity\")) == 0 else 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2hYAaFZHHgM"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    bert_model = hub.KerasLayer(BERT_URL, trainable=True)\n",
        "    preprocessor_model = hub.KerasLayer(PREPROCESSOR_URL)\n",
        "\n",
        "    input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_layer\")\n",
        "    bert_inputs = preprocessor_model(input_text)\n",
        "    bert_outputs = bert_model(bert_inputs)\n",
        "    dense = tf.keras.layers.Dense(units=256, activation=\"relu\")(bert_outputs.get(\"pooled_output\"))\n",
        "    drop = tf.keras.layers.Dropout(0.3)(dense)\n",
        "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(drop)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_text, outputs=output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WM7bdXkdt0F"
      },
      "outputs": [],
      "source": [
        "# def optimize_ds(dataset, batch_size):\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(dataset[\"train\"]).take(TAKE_SIZE)\n",
        "#     total = dataset.cardinality().numpy()\n",
        "#     dataset = dataset.batch(batch_size)\n",
        "#     dataset = dataset.map(lambda x: (x[0], 0 if x[1]==0 else 1), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#     dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "#     return dataset, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EeQcca4pdBeV"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  metrics = tf.metrics.BinaryAccuracy()\n",
        "  loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "  # train_dataset, train_data_size = load_dataset_from_tfds(\n",
        "  #     in_memory_ds, tfds_info, train_split)\n",
        "  # print(train_data_size)\n",
        "\n",
        "  steps_per_epoch = tf.data.experimental.cardinality(train_data).numpy()\n",
        "  num_train_steps = steps_per_epoch * EPOCHS\n",
        "  num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "\n",
        "  model = create_model()\n",
        "  # print(train_dataset.take(1))\n",
        "\n",
        "  optimizer = optimization.create_optimizer(\n",
        "      init_lr=INIT_LR,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      optimizer_type=\"adamw\"\n",
        "  )\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[metrics])\n",
        "\n",
        "  early_stop = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True)\n",
        "\n",
        "  \n",
        "  checkpoint_dir = os.path.dirname(CHKP_DIR)\n",
        "  # options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHKP_DIR,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      save_best_only=True,\n",
        "                                                      verbose=1)\n",
        "  latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "  if latest_checkpoint is not None:\n",
        "      print(latest_checkpoint)\n",
        "      model.load_weights(latest_checkpoint)\n",
        "\n",
        "  tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = TB_LOGS_DIR,\n",
        "                                                histogram_freq = 1)\n",
        "\n",
        "  history = model.fit(train_data, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                      validation_data=val_data,\n",
        "                      callbacks=[ cp_callback, tboard_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vIfSTpPWezwT"
      },
      "outputs": [],
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/Project/Models50k/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rkclPOm4HK5a"
      },
      "outputs": [],
      "source": [
        "model.save(SAVE_PATH + \"expertbert_120k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g3XHVe2DHX5j"
      },
      "outputs": [],
      "source": [
        "model.save(SAVE_PATH + \"expertbert_120k.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w4t4whJzHwfn"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, SAVE_PATH + \"low_level_savedmodel/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aIuDjmH4wbSu"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Project/Models50k/sentiment140_expertbert/logs/20230322-200125/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9FqWIu88P-zV"
      },
      "outputs": [],
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir \"/content/drive/MyDrive/Project/Models50k/sentiment140_expertbert/logs/20230322-200125/train\" \\\n",
        "  --name \"(optional) My latest experiment\" \\\n",
        "  --description \"(optional) Simple comparison of several hyperparameters\" \\\n",
        "  --one_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PpS_cuB3QEUd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}